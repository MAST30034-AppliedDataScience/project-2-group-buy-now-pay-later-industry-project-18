{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees to Forecast Merchant Monthly Revenue\n",
    "This notebook will employ the Gradient Boosted Trees model to forecast merchant's monthly revenue to create an overall ranking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 15:39:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/25 15:39:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/25 15:39:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Initialise a spark session\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"GBT Model\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")  # Increase driver memory\n",
    "    .config(\"spark.executor.memory\", \"16g\")  # Increase executor memory\n",
    "    .config(\"spark.executor.instances\", \"4\")  # Increase the number of executor instances\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read transaction file\n",
    "transactions = spark.read.parquet('../data/curated/flagged_fraud')\n",
    "transactions = transactions.filter(F.col(\"is_fraud\") != True) # Exclude transactions marked as fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating monthly revenue for each merchant\n",
    "monthly_revenue_df = transactions.groupBy('merchant_abn', 'order_month_year').agg(\n",
    "    F.sum('dollar_value').alias('monthly_revenue'),\n",
    "    F.count('order_id').alias('transaction_count'),\n",
    "    F.avg('fraud_probability_merchant').alias('avg_fraud_probability_merchant'),\n",
    "    F.first('name_merchant').alias('merchant_name'),\n",
    "    F.avg('take_rate').alias('avg_take_rate'),\n",
    "    F.first('revenue_band').alias('revenue_band'),\n",
    "    F.first('merchant_category').alias('merchant_category')\n",
    ")\n",
    "    \n",
    "# Aggregating consumer-level features (most common state and gender for each merchant)\n",
    "\n",
    "# Most common consumer state per merchant\n",
    "consumer_state_mode = transactions.groupBy('merchant_abn', 'state_consumer').count() \\\n",
    "    .withColumn('row_num', F.row_number().over(Window.partitionBy('merchant_abn').orderBy(F.desc('count')))) \\\n",
    "    .filter(F.col('row_num') == 1) \\\n",
    "    .select('merchant_abn', 'state_consumer')\n",
    "\n",
    "# Most common consumer gender per merchant\n",
    "consumer_gender_mode = transactions.groupBy('merchant_abn', 'gender_consumer').count() \\\n",
    "    .withColumn('row_num', F.row_number().over(Window.partitionBy('merchant_abn').orderBy(F.desc('count')))) \\\n",
    "    .filter(F.col('row_num') == 1) \\\n",
    "    .select('merchant_abn', 'gender_consumer')\n",
    "\n",
    "# Average Unemployment Rate per Merchant Month-Year\n",
    "transactions = transactions.withColumn(\"unemployment_rate_numeric\", F.col(\"unemployment_rate\").cast(\"float\"))\n",
    "\n",
    "unemployment_agg = transactions.groupBy('merchant_abn', 'order_month_year').agg(\n",
    "    F.avg('unemployment_rate_numeric').alias('avg_unemployment_rate')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 15:39:46 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+------------------+-----------------+------------------------------+--------------------+-------------------+------------+--------------------+--------------+---------------+---------------------+\n",
      "|merchant_abn|order_month_year|   monthly_revenue|transaction_count|avg_fraud_probability_merchant|       merchant_name|      avg_take_rate|revenue_band|   merchant_category|state_consumer|gender_consumer|avg_unemployment_rate|\n",
      "+------------+----------------+------------------+-----------------+------------------------------+--------------------+-------------------+------------+--------------------+--------------+---------------+---------------------+\n",
      "| 10023283211|          Mar-21| 9076.307821688919|               40|             56.40749878739966|       Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|     78.1724992275238|\n",
      "| 10142254217|          Nov-21|13097.452353073131|              315|             55.47863229844303|Arcu Ac Orci Corp...|   4.21999979019165|           b|cable, satellite,...|           NSW|           Male|    78.20253993745834|\n",
      "| 10187291046|          Jul-21| 906.4298127305271|                8|            56.333947346189554|Ultricies Digniss...| 3.2899999618530273|           b|wAtch, clock, and...|           NSW|           Male|   60.799999713897705|\n",
      "| 10187291046|          May-21|499.44547710662636|                8|             54.65314032706472|Ultricies Digniss...| 3.2899999618530273|           b|wAtch, clock, and...|           NSW|           Male|    59.68750190734863|\n",
      "| 10187291046|          Nov-21|12097.857952854954|              105|             55.98006177551826|Ultricies Digniss...| 3.2899999618530273|           b|wAtch, clock, and...|           NSW|           Male|    75.33428635370164|\n",
      "+------------+----------------+------------------+-----------------+------------------------------+--------------------+-------------------+------------+--------------------+--------------+---------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joining Datasets\n",
    "monthly_revenue_df = monthly_revenue_df.join(consumer_state_mode, on='merchant_abn', how='left') \\\n",
    "                                      .join(consumer_gender_mode, on='merchant_abn', how='left')\n",
    "\n",
    "# Join with unemployment data on both 'merchant_abn' and 'order_month_year'\n",
    "monthly_revenue_df = monthly_revenue_df.join(unemployment_agg, on=['merchant_abn', 'order_month_year'], how='left')\n",
    "\n",
    "# Show the final dataframe\n",
    "monthly_revenue_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+------------------+-----------------+------------------------------+-------------+-------------------+------------+--------------------+--------------+---------------+---------------------+----------------------+--------------------+\n",
      "|merchant_abn|order_month_year|   monthly_revenue|transaction_count|avg_fraud_probability_merchant|merchant_name|      avg_take_rate|revenue_band|   merchant_category|state_consumer|gender_consumer|avg_unemployment_rate|previous_month_revenue|      revenue_growth|\n",
      "+------------+----------------+------------------+-----------------+------------------------------+-------------+-------------------+------------+--------------------+--------------+---------------+---------------------+----------------------+--------------------+\n",
      "| 10023283211|          Apr-21| 9221.405806871098|               47|             56.03849374950703|Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|    74.54042625427246|                   0.0|                 0.0|\n",
      "| 10023283211|          Aug-21|15807.479921460479|               86|              56.2429773174978|Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|    80.79883797224178|     9221.405806871098|   0.714215842196418|\n",
      "| 10023283211|          Dec-21| 66067.74432316715|              316|             55.74664488810392|Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|    76.78892362570461|    15807.479921460479|  3.1795241652322175|\n",
      "| 10023283211|          Feb-22| 48572.88260819351|              215|             56.06942278917232|Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|    71.28418544059576|     66067.74432316715|-0.26480186200089373|\n",
      "| 10023283211|          Jan-22| 54047.30238869876|              266|             55.93287312896705|Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|    78.02368530474212|     48572.88260819351| 0.11270526858914061|\n",
      "+------------+----------------+------------------+-----------------+------------------------------+-------------+-------------------+------------+--------------------+--------------+---------------+---------------------+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating lag features to include previous month's revenue\n",
    "window_spec = Window.partitionBy('merchant_abn').orderBy('order_month_year')\n",
    "\n",
    "# Lagging features: Previous month's revenue\n",
    "monthly_revenue_df = monthly_revenue_df.withColumn(\n",
    "    'previous_month_revenue', F.lag('monthly_revenue', 1).over(window_spec)\n",
    ")\n",
    "\n",
    "# Calculate revenue growth (percentage change)\n",
    "monthly_revenue_df = monthly_revenue_df.withColumn(\n",
    "    'revenue_growth',\n",
    "    F.when(F.col('previous_month_revenue') > 0, \n",
    "           (F.col('monthly_revenue') - F.col('previous_month_revenue')) / F.col('previous_month_revenue'))\n",
    "    .otherwise(F.lit(0))  # Fill with 0 if there is no previous revenue\n",
    ")\n",
    "\n",
    "# Fill NA values for first month with 0 (no previous data available)\n",
    "monthly_revenue_df = monthly_revenue_df.fillna({'previous_month_revenue': 0, 'revenue_growth': 0})\n",
    "\n",
    "\n",
    "monthly_revenue_df = monthly_revenue_df.fillna(0)  # Filling NA values for first month\n",
    "monthly_revenue_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+--------------------+\n",
      "|merchant_abn|order_month_year|     scaled_features|\n",
      "+------------+----------------+--------------------+\n",
      "| 10023283211|          Apr-21|(960,[0,1,2,3,4,1...|\n",
      "| 10023283211|          Aug-21|(960,[0,1,2,3,4,1...|\n",
      "| 10023283211|          Dec-21|(960,[0,1,2,3,4,1...|\n",
      "| 10023283211|          Feb-22|(960,[0,1,2,3,4,1...|\n",
      "| 10023283211|          Jan-22|(960,[0,1,2,3,4,1...|\n",
      "+------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# StringIndexing categorical columns (merchant_tags, consumer_state, gender_consumer)\n",
    "indexers = [\n",
    "    StringIndexer(inputCol='state_consumer', outputCol='state_consumer_indexed', handleInvalid='keep'),\n",
    "    StringIndexer(inputCol='gender_consumer', outputCol='gender_consumer_indexed', handleInvalid='keep'),\n",
    "    StringIndexer(inputCol='merchant_category', outputCol='category_indexed', handleInvalid='keep'),\n",
    "    StringIndexer(inputCol='revenue_band', outputCol='revenue_band_indexed', handleInvalid='keep')\n",
    "]\n",
    "\n",
    "# OneHotEncoding indexed columns\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol='state_consumer_indexed', outputCol='state_consumer_encoded'),\n",
    "    OneHotEncoder(inputCol='gender_consumer_indexed', outputCol='gender_consumer_encoded'),\n",
    "    OneHotEncoder(inputCol='category_indexed', outputCol='category_encoded'),\n",
    "    OneHotEncoder(inputCol='revenue_band_indexed', outputCol='revenue_band_encoded')\n",
    "]\n",
    "\n",
    "# VectorAssembler to combine numeric features into a single feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'monthly_revenue', 'transaction_count', 'avg_fraud_probability_merchant', 'avg_unemployment_rate',\n",
    "        'state_consumer_encoded', 'gender_consumer_encoded', 'revenue_growth', 'category_encoded', 'revenue_band_encoded',\n",
    "        'avg_take_rate'\n",
    "    ], \n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# Standardizing the numeric features\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "# Fit the pipeline to the dataset\n",
    "model_pipeline = pipeline.fit(monthly_revenue_df)\n",
    "\n",
    "final_df = model_pipeline.transform(monthly_revenue_df)\n",
    "\n",
    "final_df.select('merchant_abn', 'order_month_year', 'scaled_features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the GBT Regressor\n",
    "gbt = GBTRegressor(featuresCol='scaled_features', labelCol='monthly_revenue')\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (GBT): 63462.14348098841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 15:45:59 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/09/25 15:45:59 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol='monthly_revenue', predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(gbt_predictions)\n",
    "print(f\"RMSE (GBT): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.5801295974739722\n"
     ]
    }
   ],
   "source": [
    "r2_evaluator = RegressionEvaluator(labelCol='monthly_revenue', predictionCol='prediction', metricName='r2')\n",
    "r2 = r2_evaluator.evaluate(gbt_predictions)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Parse the order_month_year column to a proper date format\n",
    "monthly_revenue_df = monthly_revenue_df.withColumn(\n",
    "    'order_month_year_date', F.to_date(F.concat(F.lit('01-'), F.col('order_month_year')), 'dd-MMM-yy')\n",
    ")\n",
    "\n",
    "# Get the most recent month per merchant\n",
    "window_spec = Window.partitionBy('merchant_abn').orderBy(F.desc('order_month_year_date'))\n",
    "latest_merchant_data = monthly_revenue_df.withColumn('row_num', F.row_number().over(window_spec)) \\\n",
    "                                         .filter(F.col('row_num') == 1) \\\n",
    "                                         .drop('row_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_month = 'Aug-24'\n",
    "future_month_df = spark.createDataFrame([(next_month,)], ['future_order_month_year'])\n",
    "future_data = latest_merchant_data.crossJoin(future_month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-----------------+-----------------+------------------------------+--------------------+-------------------+------------+--------------------+--------------+---------------+---------------------+----------------------+--------------------+---------------------+-----------------------+\n",
      "|merchant_abn|order_month_year|  monthly_revenue|transaction_count|avg_fraud_probability_merchant|       merchant_name|      avg_take_rate|revenue_band|   merchant_category|state_consumer|gender_consumer|avg_unemployment_rate|previous_month_revenue|      revenue_growth|order_month_year_date|future_order_month_year|\n",
      "+------------+----------------+-----------------+-----------------+------------------------------+--------------------+-------------------+------------+--------------------+--------------+---------------+---------------------+----------------------+--------------------+---------------------+-----------------------+\n",
      "| 10023283211|          Feb-22|48572.88260819351|              215|             56.06942278917232|       Felis Limited|0.18000000715255737|           e|furniture, home f...|           NSW|           Male|    71.28418544059576|     66067.74432316715|-0.26480186200089373|           2022-02-01|                 Aug-24|\n",
      "| 10142254217|          Feb-22| 8761.41669580623|              218|             56.29440748705243|Arcu Ac Orci Corp...|   4.21999979019165|           b|cable, satellite,...|           NSW|           Male|    76.60733880471746|     82.56213974011379|  105.11906042388328|           2022-02-01|                 Aug-24|\n",
      "| 10187291046|          Feb-22| 3165.48992443172|               26|             56.80884350094778|Ultricies Digniss...| 3.2899999618530273|           b|wAtch, clock, and...|           NSW|           Male|    88.99230626913217|     4296.839080341215| -0.2632980045926351|           2022-02-01|                 Aug-24|\n",
      "| 10192359162|          Feb-22|10514.66342879596|               23|             55.34575155431392| Enim Condimentum PC|  6.329999923706055|           a|music shops - mus...|           NSW|           Male|    84.08260801564093|    21759.649496232232| -0.5167815809433596|           2022-02-01|                 Aug-24|\n",
      "| 10206519221|          Feb-22|5828.400459934992|              145|             54.13255399137229|       Fusce Company|  6.340000152587891|           a|gift, card, novel...|           NSW|           Male|    71.57448196411133|    309.66984158167594|   17.82133704130094|           2022-02-01|                 Aug-24|\n",
      "+------------+----------------+-----------------+-----------------+------------------------------+--------------------+-------------------+------------+--------------------+--------------+---------------+---------------------+----------------------+--------------------+---------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "future_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Output column state_consumer_indexed already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m future_data \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mtransform(future_data)\n\u001b[1;32m      2\u001b[0m future_data \u001b[38;5;241m=\u001b[39m gbt_model\u001b[38;5;241m.\u001b[39mtransform(future_data)\n\u001b[1;32m      3\u001b[0m future_predictions \u001b[38;5;241m=\u001b[39m future_data\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerchant_abn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerchant_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerchant_category\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuture_order_month_year\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/ml/pipeline.py:304\u001b[0m, in \u001b[0;36mPipelineModel._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m--> 304\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/ml/wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\u001b[38;5;241m.\u001b[39mtransform(dataset\u001b[38;5;241m.\u001b[39m_jdf), dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column state_consumer_indexed already exists."
     ]
    }
   ],
   "source": [
    "future_data = model_pipeline.transform(future_data)\n",
    "future_data = gbt_model.transform(future_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+-----------------------+------------------+\n",
      "|merchant_abn|       merchant_name|   merchant_category|future_order_month_year| projected_revenue|\n",
      "+------------+--------------------+--------------------+-----------------------+------------------+\n",
      "| 10023283211|       Felis Limited|furniture, home f...|                 Aug-24| 41999.13969730871|\n",
      "| 10142254217|Arcu Ac Orci Corp...|cable, satellite,...|                 Aug-24| 7042.474009394071|\n",
      "| 10187291046|Ultricies Digniss...|wAtch, clock, and...|                 Aug-24|3774.7450293843253|\n",
      "| 10192359162| Enim Condimentum PC|music shops - mus...|                 Aug-24| 11886.41819145374|\n",
      "| 10206519221|       Fusce Company|gift, card, novel...|                 Aug-24| 3173.254384034889|\n",
      "+------------+--------------------+--------------------+-----------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "future_predictions = future_data.select('merchant_abn', 'merchant_name', 'merchant_category','future_order_month_year', 'prediction')\n",
    "future_predictions = future_predictions.withColumnRenamed('prediction', 'projected_revenue')\n",
    "future_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+-----------------------+------------------+\n",
      "|merchant_abn|       merchant_name|   merchant_category|future_order_month_year| projected_revenue|\n",
      "+------------+--------------------+--------------------+-----------------------+------------------+\n",
      "| 76626119831|Tristique Pellent...|antique shops - s...|                 Aug-24|1412890.6763885315|\n",
      "| 43186523025|Lorem Ipsum Sodal...|florists supplies...|                 Aug-24|1152410.4677365497|\n",
      "| 49505931725|Suspendisse Ac As...|digital goods: bo...|                 Aug-24|1145764.5631390007|\n",
      "| 80518954462|Neque Sed Dictum ...|computers, compUt...|                 Aug-24| 890020.7811315439|\n",
      "| 24852446429|      Erat Vitae LLP|florists supplies...|                 Aug-24|  851622.291253416|\n",
      "| 45629217853|    Lacus Consulting|gift, Card, novel...|                 Aug-24| 739781.2841024923|\n",
      "| 60956456424|Ultricies Digniss...|gift, card, Novel...|                 Aug-24| 647283.4310751271|\n",
      "| 49891706470|Non Vestibulum In...|teNt and awning s...|                 Aug-24| 585846.1967241862|\n",
      "| 79417999332|Phasellus At Company|gift, card, novel...|                 Aug-24|  559748.383452795|\n",
      "| 72472909171|   Nullam Consulting|digiTal goods: bo...|                 Aug-24| 513378.9781082555|\n",
      "+------------+--------------------+--------------------+-----------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBT_predictions = future_predictions.orderBy(F.col('projected_revenue').desc())\n",
    "\n",
    "# Show the top 10 merchants by predicted revenue\n",
    "GBT_predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "GBT_predictions.write.parquet('../data/curated/GBT_ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
